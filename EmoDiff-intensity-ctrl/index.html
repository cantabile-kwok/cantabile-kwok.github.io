<html><head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML" async></script>
<script type="text/x-mathjax-config;executed=true">
    window.MathJax.Hub.Config({
        showProcessingMessages: false, //关闭js加载过程信息
        messageStyle: "none", //不显示信息
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
            inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
            displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
            skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
        },
        "HTML-CSS": {
            availableFonts: ["STIX", "TeX"], //可选字体
            showMathMenu: false //关闭右击菜单显示
        }
    });
    window.MathJax.Hub.Queue(["Typeset", MathJax.Hub,document.getElementsByClassName("ck-content")]);
</script>
    <meta charset="utf-8">
    <title>Audio Samples from "Unsupervised Word-Level Prosody Tagging for Controllable Speech Synthesis"</title>

    <!-- Bootstrap core CSS -->
    <!-- <link href="./bootstrap/dist/css/bootstrap.min.css" rel="stylesheet"> -->

    <style>
      .bd-placeholder-img {
        font-size: 1.125rem;
        text-anchor: middle;
        -webkit-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
      }

      @media (min-width: 768px) {
        .bd-placeholder-img-lg {
          font-size: 3.5rem;
          /* display: inline; */
        }
      }
    </style>
</head>

<!--<link href="./dist/css/bootstrap.min.css" rel="stylesheet">-->
<body data-new-gr-c-s-check-loaded="14.1027.0" data-gr-ext-installed="">
  <div class="container">
      <center>
    <div style="background:#EAEAEA;color:#000;width:1000">
        <br />
      <b><font size=6><center>Audio Samples from</center></font></b> <br />
          <center><font size=4.2>"EmoDiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label Guidance", Submitted to ICASSP2023</font></center></h1>
      <p class="lead"><center><i>Yiwei Guo, Chenpeng Du, Xie Chen, Kai Yu</i></center></p>
      <!-- <br /> -->
      <p class="lead"><center>cantabile_kwok@sjtu.edu.cn</center></p>
      <p class="lead"><center><font color='red'><b>NOTE: this page is still under construction.</b></font></center></p>
    </div>
    </center>
    <br />
    <b><center><font size=5>1. Emotional TTS Quality</font></center></b><br/>
    <center>
        <table class="table" style="width: 50%; max-width: 50%;margin-left: 100px; margin-right: 100px;">
            <tbody>
            <tr> 
                <td width="100" style="word-break:normal;">
                    This part presents the quality of compared systems, corresonding to Section 4.2 in the paper.     
                    Note that all the audio on this page is synthesized from HifiGAN implemented in <a href="https://github.com/kan-bayashi/ParallelWaveGAN">this repo</a>, except ground truth.
                    All the utterances are from <a href="https://github.com/HLTSingapore/Emotional-Speech-Data/">ESD</a> speaker ID 0015.
                    <br/><br/>
                    <b>GT</b>: Ground truth recording.
                    <br />
                    <b>GT (voc.)</b>: Ground truth mel-spectrogram + HifiGAN.
                    <br/>
                    <b>MixedEmotion</b>: Proposed in <a href="https://arxiv.org/abs/2208.05890">this paper</a>. We use the <a href="https://github.com/KunZhou9646/Mixed_Emotions">official code</a>.
                    It is an autoregressive model based on relative attributes rank to pre-calculate intensity values for training. 
                    It much resembles <a href="https://arxiv.org/abs/2201.03967">Emovox</a> for intensity controllable emotion conversion.
                    <br/>
                    <b>GradTTS w/ emo label</b>: a conditional <a href="https://proceedings.mlr.press/v139/popov21a.html">GradTTS</a> model with hard emotion labels as input. It therefore does not have intensity controllability, but should have good sample quality, as a certified acoustic model.
                    <br/>
                    <b>EmoDiff</b>: Proposed intensity controllable emotional TTS model.
                </td>
            </tr>
            </tbody>
        </table>
        <br/>
    <table class="table">
        <tbody>
        <tr>
            <td></td>
            <th>GT</th>
            <th>Raw_FSP</th>
            <th>PLP_MDN</th>
            <th>WLP_predict</th>
        </tr>
        <tr>
            <td>LJ050-0179</td>
            <td><audio src="./audio/naturalness/GT/LJ050-0179_gen.wav" controls=""></audio></td>
            <td><audio src="./audio/naturalness/raw_fastspeech/LJ050-0179_gen.wav" controls=""></audio></td>
            <td><audio src="./audio/naturalness/cpd_phone/LJ050-0179_gen.wav" controls=""></audio></td>
            <td><audio src="./audio/naturalness/wl_cluster/LJ050-0179_gen.wav" controls=""></audio></td>
        </tr>
    </tbody></table></center>
<br />
<HR align=center width=1000>
<b><center><font size=5>2. Controllability of Emotion Intensity</font></center></b><br />
<center>
    <table class="table" style="width: 50%; max-width: 50%;margin-left: 100px; margin-right: 100px;">
        <tbody>
        <tr> 
            <td width="100" style="word-break:normal;">Text goes here.
            </td>
        </tr>
        </tbody>
    </table>
    <br/><br/>
    <table class="table">
        <tbody><tr><th scope="col" colspan="2" bgcolor="#F8F8F8">International Business Machines <font color='#FF0000'>Corporation</font>, <br/>and a panel of psychiatric and psychological experts. </th>
            <th><font color='#FFFFFF'>White</font></th>
            <th scope="col" colspan="2" bgcolor="#F8F8F8">Both Director Hoover and Belmont expressed to the <font color='#FF0000'>Commission</font> the great <br/> concern of the FBI, which is shared by the Secret Service</th></tr>
        <tr>
            <th></th>
            <th></th>
            <th></th>
            <th></th>
            <th></th>
        </tr>
        <tr>
            <td>GT with tag 0</td>
            <td><audio src="./audio/control-in-paper/GT/LJ050-0047_gen.wav" controls=""></audio></td>
            <td></td>
            <td>GT with tag 0</td>
            <td><audio src="./audio/control-in-paper/GT/LJ050-0071_gen.wav" controls=""></audio></td>
        </tr>
        
        </tbody>
    </table>
</center>
<br/>
<br/>


<HR align=center width=1000>

<center>
    <br/>
    <table class="table" style="width: 50%; max-width: 50%;margin-left: 100px; margin-right: 100px;">
        <tbody>
        <tr> 
            <td width="100" style="word-break:normal;">
                In addition to the experiments mentioned in the paper, we also present a similar demo for word-level prosody control,
                which might be easier to understand.  
                Here, the controlled words can come from different leaf nodes.
                For each of those words, we synthesize it using the five prosody tags in its leaf node.
                For each tag, we concatenate some words in the training set of recordings that have this specific ground truth tag.
                These concatenated words are called <b>reference words</b>.
                Listeners can verify that the controlled word in the right column has the similar prosody with the reference words at left.
                <br/>
                The mel-spectrograms are also shown so as to depict the prosodic variations.
            </td>
        </tr>
        </tbody>
    </table>
    <br/>
    <table class="table">
        <tbody><tr><td scope="col" colspan="4" bgcolor="#F8F8F8" align='center'><b>And the respective <font color='#FF0000'>responsibilities</font> for any further investigation that may be required.</b></td>
        </tr>
        <tr>
            <td></td>
            <th>Reference Words</th>
            <th colspan="2">Synthesized Speech</th>
        </tr>
        <tr>
            <td>0</td>
            <td><audio src="./audio/control/e(0).m4a" controls=""></audio></td>
            <td><audio src="./audio/control/LJ050-0114-responsibilities(4)0.wav" controls=""></audio></td>
            <!-- <td rowspan="5"><img src="LJ050-0114-mel.png" width="400"/></td> -->
        </tr>
        
    </tbody></table>
</center>



  </div>
<br />
<br/>
</body><style id="stylish-2" class="stylish" type="text/css">#notebook-container * {

font-family: Consolas, "微软雅黑"

}</style><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>